{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-2.12.1.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Importing necessary dependencies\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.utils import shuffle\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.model_selection import train_test_split \n",
    "from datetime import datetime\n",
    "import os\n",
    "from os.path import isdir, join\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "# Math\n",
    "import numpy as np\n",
    "from scipy.fftpack import fft\n",
    "from scipy import signal\n",
    "from scipy.io import wavfile\n",
    "import librosa\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import IPython.display as ipd\n",
    "import librosa.display\n",
    "\n",
    "import plotly.offline as py\n",
    "py.init_notebook_mode(connected=True)\n",
    "import plotly.graph_objs as go\n",
    "import plotly.tools as tls\n",
    "import pandas as pd\n",
    "\n",
    "from plotly.subplots import make_subplots\n",
    "%matplotlib inline\n",
    "import os\n",
    "import numpy as np\n",
    "import librosa\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy import signal\n",
    "from scipy.io import wavfile\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating models\n",
    "# causal conv\n",
    "def __causal_gated_conv1D(x=None, filters=16, length=6, strides=1):\n",
    "    def causal_gated_conv1D(x, filters, length, strides):\n",
    "        x_in_1 = layers.Conv1D(filters=filters // 2,\n",
    "                               kernel_size=length,\n",
    "                               dilation_rate=strides, \n",
    "                               strides=1,\n",
    "                               padding=\"causal\")(x)\n",
    "        x_sigmoid = layers.Activation(activation=\"sigmoid\")(x_in_1)\n",
    "\n",
    "        x_in_2 = layers.Conv1D(filters=filters // 2,\n",
    "                               kernel_size=length,\n",
    "                               dilation_rate=strides,  \n",
    "                               strides=1,\n",
    "                               padding=\"causal\")(x)\n",
    "        x_tanh = layers.Activation(activation=\"tanh\")(x_in_2)\n",
    "\n",
    "        x_out = layers.Multiply()([x_sigmoid, x_tanh])\n",
    "\n",
    "        return x_out\n",
    "\n",
    "    if x is None:\n",
    "        return lambda _x: causal_gated_conv1D(x=_x, filters=filters, length=length, strides=strides)\n",
    "    else:\n",
    "        return causal_gated_conv1D(x=x, filters=filters, length=length, strides=strides)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Net(input_shape, classes, width_multiply=1):\n",
    "    _x_in = layers.Input(shape=input_shape)\n",
    "\n",
    "    # 1 block\n",
    "    _x_up = __causal_gated_conv1D(filters=16 * width_multiply, length=3)(_x_in)\n",
    "    _x_down = __causal_gated_conv1D(filters=16 * width_multiply, length=6)(_x_in)\n",
    "    _x = layers.Concatenate()([_x_up, _x_down])\n",
    "\n",
    "    # 2 block\n",
    "    _x_up = __causal_gated_conv1D(filters=8 * width_multiply, length=3)(_x)\n",
    "    _x_down = __causal_gated_conv1D(filters=8 * width_multiply, length=6)(_x)\n",
    "    _x = layers.Concatenate()([_x_up, _x_down])\n",
    "\n",
    "    # 3 block\n",
    "    _x_up = __causal_gated_conv1D(filters=8 * width_multiply, length=3)(_x)\n",
    "    _x_down = __causal_gated_conv1D(filters=8 * width_multiply, length=6)(_x)\n",
    "    _x_concat = layers.Concatenate()([_x_up, _x_down])\n",
    "\n",
    "    _x = layers.Add()([_x, _x_concat])\n",
    "\n",
    "    # 4 block\n",
    "    _x_loop1 = __causal_gated_conv1D(filters=16 * width_multiply, length=3, strides=3)(_x)\n",
    "    _x = layers.Add()([_x, _x_loop1])\n",
    "\n",
    "    # 5 block\n",
    "    _x_loop2 = __causal_gated_conv1D(filters=16 * width_multiply, length=3, strides=2)(_x)\n",
    "    _x = layers.Add()([_x, _x_loop2])\n",
    "\n",
    "    # 6 block\n",
    "    _x_loop3 = __causal_gated_conv1D(filters=16 * width_multiply, length=3, strides=2)(_x)\n",
    "    _x = layers.Add()([_x, _x_loop3])\n",
    "\n",
    "    # 7 block\n",
    "    _x_forward = __causal_gated_conv1D(filters=16 * width_multiply, length=3, strides=2)(_x)\n",
    "\n",
    "    # 8 block\n",
    "    _x_loop4 = __causal_gated_conv1D(filters=32 * width_multiply, length=3, strides=2)(_x)\n",
    "\n",
    "    # output\n",
    "    _x = layers.Concatenate()([_x_loop2, _x_loop3, _x_forward, _x_loop4])\n",
    "    _x = layers.Conv1D(filters=classes, kernel_size=1)(_x)\n",
    "    _x = layers.GlobalAveragePooling1D()(_x)\n",
    "    _x = layers.Activation(\"softmax\")(_x)\n",
    "\n",
    "    model = models.Model(inputs=_x_in, outputs=_x)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# Load the training data\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m X_train \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mload(\u001b[39m'\u001b[39m\u001b[39mtraining_data.npy\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m      3\u001b[0m y_train \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mload(\u001b[39m'\u001b[39m\u001b[39mtraining_labels.npy\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m      5\u001b[0m \u001b[39m# Load the validation data (\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "# Load the training data\n",
    "X_train = np.load('/home/sae/training_data.npy')\n",
    "y_train = np.load('/home/sae/training_labels.npy')\n",
    "\n",
    "# Load the validation data (\n",
    "X_validation = np.load('/home/sae/validation_data.npy')\n",
    "y_validation = np.load('/home/sae/validation_labels.npy')\n",
    "\n",
    "# Load the test data\n",
    "X_test = np.load('/home/sae/testing_data.npy')\n",
    "y_test = np.load('/home/sae/testing_labels.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#K fold validation & precision/recall calculation\n",
    "from sklearn.model_selection import StratefiedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "k = 10 # 10 fold validation\n",
    "cv = StratefiedKFold(n_split = k, shuffle = True, random_state = 42)\n",
    "\n",
    "#Store accuracy and precision/recall\n",
    "results = []\n",
    "fold_precisions = []\n",
    "fold_recalls = []\n",
    "\n",
    "#F1 scores\n",
    "fold_f1_scores = []\n",
    "# Initialize an array of threshold values (e.g., from 0.1 to 0.9)\n",
    "thresholds = np.arange(0.1, 1.0, 0.1)\n",
    "\n",
    "le = LabelEncoder()\n",
    "num_epochs = 3\n",
    "num_batch_size = 32\n",
    "\n",
    "# Combine training, validation, and testing data\n",
    "X_combined = np.concatenate((X_train, X_validation, X_test))\n",
    "y_combined = np.concatenate((y_train, y_validation, y_test))\n",
    "\n",
    "# Perform k-fold cross-validation\n",
    "for train_idx, validation_idx, test_idx in cv.split(X_combined, y_combined):\n",
    "    X_train_fold, y_train_fold = X_combined[train_idx], y_combined[train_idx]\n",
    "    X_validation_fold, y_validation_fold = X_combined[validation_idx], y_combined[validation_idx]\n",
    "    X_test_fold, y_test_fold = X_combined[test_idx], y_combined[test_idx]\n",
    "    \n",
    "    y_train_encoded = to_categorical(le.fit_transform(y_train))\n",
    "    y_validation_encoded = to_categorical(le.transform(y_validation))\n",
    "    y_test_encoded = to_categorical(le.transform(y_test))\n",
    "\n",
    "    #Compile a model\n",
    "    model = Net(input_shape=(40,87), classes=2,width_multiply=2) \n",
    "    # Compile the model\n",
    "    model.compile(loss='binary_crossentropy', metrics=['accuracy'], optimizer='adam')\n",
    "    # # Display model architecture summary\n",
    "    # model.summary()\n",
    "    \n",
    "    # Train your model on X_train_fold and y_train_fold\n",
    "    history = model.fit(X_train_fold, y_train_encoded, batch_size=num_batch_size, epochs=num_epochs, validation_data=(X_validation_fold, y_validation_encoded), verbose=1)\n",
    "\n",
    "    # Make predictions on the testing set\n",
    "    y_test_pred = model.predict(X_test_fold)\n",
    "\n",
    "    # Calculate accuracy for this fold\n",
    "    fold_accuracy = accuracy_score(y_test_fold, y_test_pred)\n",
    "    results.append(fold_accuracy)\n",
    "    \n",
    "     # Convert predictions and true labels to binary format for precision and recall calculation\n",
    "    y_test_pred_binary = np.argmax(y_test_pred, axis=1)\n",
    "    y_test_fold_binary = np.argmax(y_test_encoded, axis=1)\n",
    "\n",
    "    # Calculate precision and recall for this fold\n",
    "    fold_precision = precision_score(y_test_fold_binary, y_test_pred_binary)\n",
    "    fold_recall = recall_score(y_test_fold_binary, y_test_pred_binary)\n",
    "    \n",
    "    fold_precisions.append(fold_precision)\n",
    "    fold_recalls.append(fold_recall)\n",
    "    \n",
    "    f1_scores = []\n",
    "    for threshold in thresholds:\n",
    "        y_test_pred_thresholded = (y_test_pred[:, 1] > threshold).astype(int)  # Adjust the column index if needed\n",
    "\n",
    "        # Calculate TP, FP, FN for the current threshold\n",
    "        TP = np.sum((y_test_fold_binary == 1) & (y_test_pred_thresholded == 1))\n",
    "        FP = np.sum((y_test_fold_binary == 0) & (y_test_pred_thresholded == 1))\n",
    "        FN = np.sum((y_test_fold_binary == 1) & (y_test_pred_thresholded == 0))\n",
    "\n",
    "        # Calculate precision and recall for the current threshold\n",
    "        precision = TP / (TP + FP) if (TP + FP) > 0 else 0\n",
    "        recall = TP / (TP + FN) if (TP + FN) > 0 else 0\n",
    "\n",
    "        # Calculate F1 score using precision and recall\n",
    "        f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "\n",
    "        f1_scores.append(f1)\n",
    "\n",
    "    fold_f1_scores.append(f1_scores)\n",
    "\n",
    "# Calculate mean and standard deviation of accuracy scores\n",
    "mean_accuracy = np.mean(results)\n",
    "std_accuracy = np.std(results)\n",
    "\n",
    "# Calculate mean precision and recall scores over all folds\n",
    "mean_precision = np.mean(fold_precisions)\n",
    "mean_recall = np.mean(fold_recalls)\n",
    "\n",
    "# Calculate mean F1 scores over all folds\n",
    "mean_f1_scores = np.mean(fold_f1_scores, axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Print results\n",
    "\n",
    "for i in range(0, k):\n",
    "    print(\"Accuracy: \", results[i], \"  Precision: \", fold_precision[i], \"  Recall: \", fold_recall[i], \" F1 Score: \", fold_f1_scores[i])\n",
    "\n",
    "print(\"Mean accuracy: \",  mean_accuracy, \"  Mean precision: \", mean_precision, \"  Mean recall: \", mean_recall, \" Mean F1 Score: \", mean_f1_scores)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot the F1 curve\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(thresholds, mean_f1_scores, marker='o', linestyle='-')\n",
    "plt.xlabel('Threshold')\n",
    "plt.ylabel('F1 Score')\n",
    "plt.title('F1 Curve')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "newconda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18 | packaged by conda-forge | (main, Aug 30 2023, 03:49:32) \n[GCC 12.3.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2df73002193cefbfa9243a6efa2b74af79e3047145117f20857a75b11408ac59"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
